# G√©n√©ration de Donn√©es avec LLM

Ce projet utilise d√©sormais une LLM (Language Model) pour g√©n√©rer des donn√©es d'employ√©s plus r√©alistes pour la base de donn√©es.

## üöÄ Configuration

### 1. Installation des d√©pendances

```bash
pip install -r requirements.txt
```

Le package `openai` sera install√© automatiquement.

### 2. Configuration de la cl√© API OpenAI

**Option A : Variable d'environnement (recommand√©e)**

```bash
# Windows PowerShell
$env:OPENAI_API_KEY="votre_cle_api_openai"

# Windows CMD
set OPENAI_API_KEY=votre_cle_api_openai

# Linux/Mac
export OPENAI_API_KEY=votre_cle_api_openai
```

**Option B : Fichier .env (optionnel)**

Cr√©ez un fichier `.env` √† la racine du projet :
```
OPENAI_API_KEY=votre_cle_api_openai
```

### 3. Configuration dans config.yaml

La configuration LLM se trouve dans `config.yaml` :

```yaml
llm_data_generation:
  enabled: true                    # Active/d√©sactive la g√©n√©ration LLM
  provider: "openai"              # Fournisseur LLM
  model: "gpt-4o-mini"           # Mod√®le √† utiliser (gpt-4o-mini est √©conomique)
  api_key: "${OPENAI_API_KEY}"   # Variable d'environnement
  temperature: 0.7                # Cr√©ativit√© (0-1)
  max_tokens: 500                  # Tokens max par r√©ponse
  batch_size: 20                  # Profils g√©n√©r√©s par requ√™te
```

**Mod√®les recommand√©s :**
- `gpt-4o-mini` : √âconomique et rapide (recommand√©)
- `gpt-4o` : Plus performant mais plus cher
- `gpt-3.5-turbo` : Alternative √©conomique

## üìä Utilisation

### G√©n√©rer la base de donn√©es avec LLM

```bash
python create_database.py
```

Le script va :
1. V√©rifier si la LLM est activ√©e et disponible
2. G√©n√©rer les profils d'employ√©s par batches (20 par d√©faut)
3. Utiliser la g√©n√©ration al√©atoire en fallback si la LLM √©choue
4. Cr√©er la base de donn√©es avec les donn√©es g√©n√©r√©es

### Exemple de sortie

```
============================================================
CREATION DE LA BASE DE DONNEES TURNOVER
============================================================

1. Creation des tables...
OK Tables creees

2. Generation des donnees d'employes...
‚úì LLM activ√©: gpt-4o-mini
G√©n√©ration de 1000 profils avec LLM (50 batches)...
  Batch 1/50 (20 profils)... ‚úì 20 profils g√©n√©r√©s
  Batch 2/50 (20 profils)... ‚úì 20 profils g√©n√©r√©s
  ...
OK 1000 employes generes
```

## üéØ Avantages de la g√©n√©ration LLM

1. **Donn√©es plus r√©alistes** : 
   - Noms vari√©s et coh√©rents
   - √Çges adapt√©s aux niveaux de poste
   - Distributions naturelles

2. **Coh√©rence** :
   - Corr√©lations r√©alistes entre variables
   - Profils cr√©dibles

3. **Vari√©t√©** :
   - Nombreux noms fran√ßais diff√©rents
   - Diversit√© dans les profils

## ‚öôÔ∏è D√©sactiver la g√©n√©ration LLM

Si vous souhaitez utiliser uniquement la g√©n√©ration al√©atoire (rapide, gratuit) :

```yaml
llm_data_generation:
  enabled: false
```

Ou commentez la ligne dans `config.yaml`.

## üí∞ Co√ªts estim√©s

Pour 1000 employ√©s avec `gpt-4o-mini` :
- ~50 appels API (20 profils par batch)
- Co√ªt estim√© : **~0.10-0.20 USD** (selon OpenAI)

Pour r√©duire les co√ªts :
- Augmentez `batch_size` (ex: 30-50) dans `config.yaml`
- Utilisez `gpt-3.5-turbo` si disponible

## üîß D√©pannage

### Erreur : "Cl√© API OpenAI non trouv√©e"

**Solution** : V√©rifiez que la variable d'environnement est bien d√©finie :
```bash
echo $OPENAI_API_KEY  # Linux/Mac
echo %OPENAI_API_KEY%  # Windows CMD
$env:OPENAI_API_KEY    # Windows PowerShell
```

### Erreur : "Biblioth√®que openai non disponible"

**Solution** :
```bash
pip install openai>=1.0.0
```

### La g√©n√©ration est lente

C'est normal ! La LLM prend du temps. Pour acc√©l√©rer :
- R√©duisez `batch_size` (mais augmente le nombre d'appels)
- Ou d√©sactivez la LLM avec `enabled: false`

### Certains profils √©chouent

Le script passe automatiquement en mode fallback (g√©n√©ration al√©atoire) pour les batches qui √©chouent. C'est normal et garanti de fonctionner.

## üìù Notes

- Les donn√©es g√©n√©r√©es sont **anonymes** et **fictives**
- La LLM respecte les contraintes (d√©partements, niveaux, etc.)
- Le calcul des salaires reste automatique et coh√©rent
- Compatible avec l'ancien syst√®me (fallback automatique)


